{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping news articles with TheGuardianAPI and BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook creates a dataset for Natural Language Processing (NLP) by scraping news articles from the Guardian. \n",
    "\n",
    "First, it collects the location (urls) of the desired news articles using the Guardian Open Platform, specifically the content API endpoint. Then, it scrapes the text from each with the BeautifulSoup python library and saves it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to obtain the text from a single article first, to get familiar with the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "\n",
    "apikey = os.getenv('GUARDIAN_APIKEY')\n",
    "BASE_URL = \"http://content.guardianapis.com/search?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Hong Kong AND election\"\n",
    "query_fields = \"body\"\n",
    "from_date = \"2021-9-21T00:00:00\"\n",
    "to_date = \"2021-9-21T08:00:00\"\n",
    "query_url = f\"{BASE_URL}&api-key={apikey}\" \\\n",
    "            f\"&q={query}\" \\\n",
    "            f\"&query-fields={query_fields}\" \\\n",
    "            f\"&from-date={from_date}\" \\\n",
    "            f\"&to-date={to_date}\" # \\\n",
    "            # f\"&show-fields=body\"\n",
    "\n",
    "# query_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n",
      "\n",
      "Headers: {'Access-Control-Allow-Credentials': 'true', 'Access-Control-Allow-Origin': '*', 'Cache-Control': 'max-age=0, no-cache=\"set-cookie\"', 'Content-Encoding': 'gzip', 'Content-Type': 'application/json', 'Date': 'Tue, 21 Sep 2021 19:09:08 GMT', 'Server': 'Concierge', 'Set-Cookie': 'AWSELB=75B9BD811C5C032EDEF76366759629DCCB8726D7A37401C19A3457074430A4AA14CD1FA6CBE4519DDF3CD336789F71716B110728D8FF3418C2C759D07E5F767DD54D1B7752;PATH=/;MAX-AGE=86400', 'Via': 'kong/0.14.0', 'X-Kong-Proxy-Latency': '1', 'X-Kong-Upstream-Latency': '12', 'X-RateLimit-Limit-day': '5000', 'X-RateLimit-Limit-minute': '720', 'X-RateLimit-Remaining-day': '4980', 'X-RateLimit-Remaining-minute': '719', 'Content-Length': '419', 'Connection': 'keep-alive'}\n",
      "\n",
      "{'response': {'currentPage': 1,\n",
      "              'orderBy': 'relevance',\n",
      "              'pageSize': 10,\n",
      "              'pages': 1,\n",
      "              'results': [{'apiUrl': 'https://content.guardianapis.com/world/2021/sep/21/hong-kong-leader-defends-election-after-single-opposition-figure-makes-it-to-1500-strong-committee',\n",
      "                           'id': 'world/2021/sep/21/hong-kong-leader-defends-election-after-single-opposition-figure-makes-it-to-1500-strong-committee',\n",
      "                           'isHosted': False,\n",
      "                           'pillarId': 'pillar/news',\n",
      "                           'pillarName': 'News',\n",
      "                           'sectionId': 'world',\n",
      "                           'sectionName': 'World news',\n",
      "                           'type': 'article',\n",
      "                           'webPublicationDate': '2021-09-21T05:46:48Z',\n",
      "                           'webTitle': 'Hong Kong leader defends election '\n",
      "                                       'after single non-establishment figure '\n",
      "                                       'picked for 1,500-strong committee',\n",
      "                           'webUrl': 'https://www.theguardian.com/world/2021/sep/21/hong-kong-leader-defends-election-after-single-opposition-figure-makes-it-to-1500-strong-committee'}],\n",
      "              'startIndex': 1,\n",
      "              'status': 'ok',\n",
      "              'total': 1,\n",
      "              'userTier': 'developer'}}\n"
     ]
    }
   ],
   "source": [
    "r = requests.get(query_url)\n",
    "print(f\"Status code: {r.status_code}\\n\")\n",
    "print(f\"Headers: {r.headers}\\n\")\n",
    "pprint(r.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the request was successful, and we printed the contents in pretty-printed JSON format for readability. We could demand that the field `body` be returned as well, as a potential shortcut to calling `requests` a second time on the individual article urls. This, however, has some subtle behaviour, so we will go for the traditional route. Now, let's see the url of the article we downloaded!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.theguardian.com/world/2021/sep/21/hong-kong-leader-defends-election-after-single-opposition-figure-makes-it-to-1500-strong-committee\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(r.json()['response']['results'])):\n",
    "    url = r.json()['response']['results'][i]['webUrl']\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we requests the article itself and parse it with BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = requests.get(url)\n",
    "soup_article = BeautifulSoup(article.content, 'html.parser')\n",
    "# print(soup_article.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We list all `p` tags with the specified properties (i.e. class and position inside a certain `div`), we extract and collate the text. And we are done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hong Kong’s chief executive, Carrie Lam, has defended the weekend’s election of a powerful committee to appoint senior leaders, after just one candidate not strictly aligned with the establishment camp was elected among the 1,500 positions. Under an overhauled electoral system, dubbed “patriots rule Hong Kong”, fewer than 5,000 people were eligible to vote on Sunday, choosing from candidates who had already been vetted for political loyalty and cleared of being a national security threat. The results saw primarily Beijing loyalists and pro-establishment figures elected to the committee. The group will choose nearly half the Hong Kong legislature next year, and a new leader for the territory. Just two candidates described by local media as not strictly from the establishment ranks , were able to run. Only one, Tik Chi-yuen, was elected. On Tuesday at her regular press briefing Lam rejected criticisms of the lack of opposition figures among the candidates and eligible voters, saying “non-patriots” were not allowed to enter the establishment of Hong Kong as they may undermine it. “You asked why so few candidates who are not from the pro-establishment camp got elected. How can I answer this question? There was only one objective behind the approved electoral system – to ensure patriots administer Hong Kong,” she said. “Under the mechanism diverse views are welcome … They must uphold the basic law and swear allegiance to the People’s Republic of China and the Hong Kong SAR [Special Administrative Region]. I believe these are reasonable requirements.” The new system was introduced by Beijing, amid a suite of measures designed to crack down on the pro-democracy movement in Hong Kong following months of massive protests. Under the electoral changes, the election committee will appoint 40 of Hong Kong’s 90 legislative seats. Another 30 will be chosen by special interest groups and just 20 will be directly elected. Sunday’s 5,000 voters were a fraction of the more than 230,000 Hong Kongers who were eligible to vote for the committee in 2016. Beijing and Hong Kong authorities claims it will ensure “anti-China elements will be barred from office, but critics say it is bringing Hong Kong’s political system closer to that of the Communist Party-ruled mainland China. “The improved electoral system will effectively improve people’s standard of living and livelihood and help Hong Kong better integrate into… our country,” Lam said on Tuesday. “This is a form of democratic election because the members are returned by an election. When it comes to elections it’s not one size fits all - one has to take into account the actual situation of the place.” Lam said individuals from the non pro-establishment or pro-democracy camps were welcome to run for elections, but whether they were eligible would be decided by the government’s review committee. Last week seven pro-democracy district councillors were disqualified, after being accused of making “invalid oaths”. Councillors said they were not given reasons for their disqualifications, which they labeled “arbitrary”.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body = soup_article.find_all('div', class_='article-body-commercial-selector')\n",
    "ps = body[0].find_all('p', class_='dcr-s23rjr')\n",
    "par_list = [p.text for p in ps]\n",
    "final = \" \".join(par_list)\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would imagine there should be a shortcut to all this, since the API can return the body in HTML if prompted (calling `show-fields=body` in the api call above). This, however, contains certain artifacts (such as related content) which I haven't been able to remove yet. Ideally, there should be a switch in the API. If this worked, the following snippet of code would retrieve the whole text without a second round of HTTP requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# article_body = r.json()['response']['results'][0]['fields']['body']\n",
    "# article_body\n",
    "# new_soup = BeautifulSoup(article_body, 'html.parser')\n",
    "# ps2 = new_soup.find_all('p')\n",
    "# par_list = [p.text for p in ps2]\n",
    "# final2 = \" \".join(par_list)\n",
    "# final2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab article urls and store them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can repeat this process to grab as many articles as needed. We will search all articles containing the word \"Hong Kong\" in the body, from Jan 1 2019. This query returns thousands of hits, over many pages. It is convenient to increase the `page-size` of the server response to the maximum value (200) and to use a slightly different syntax for the HTTP request, so it's easier to iterate over the parameter `page`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_ENDPOINT = \"http://content.guardianapis.com/search\"\n",
    "\n",
    "my_params = {\n",
    "    'api-key': apikey,\n",
    "    'q': \"Hong Kong\",\n",
    "    'query-fields': \"body\",\n",
    "    'from-date': \"2019-1-1\",\n",
    "    'page-size': 200,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab the first 15 pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading page 5...\n",
      "Downloading page 10...\n",
      "Downloading page 15...\n",
      "Finished downloading.\n"
     ]
    }
   ],
   "source": [
    "def get_all_results(base_url, params):\n",
    "\n",
    "    all_results = []\n",
    "    current_page = 1\n",
    "    total_pages = 15\n",
    "    while current_page <= total_pages:\n",
    "        if current_page % 5 == 0: print(f\"Downloading page {current_page}...\")\n",
    "        params['page'] = current_page\n",
    "        try:\n",
    "            r = requests.get(base_url, params)\n",
    "            r.raise_for_status()\n",
    "        except requests.exceptions.RequestException as err:\n",
    "            raise SystemExit(err)\n",
    "        data = r.json()\n",
    "        all_results.extend(data['response']['results'])\n",
    "        current_page += 1\n",
    "        \n",
    "    print(\"Finished downloading.\")\n",
    "    return all_results\n",
    "\n",
    "all_results = get_all_results(API_ENDPOINT, my_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We grabbed 3000 articles! The metadata for the first one:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'world/2021/sep/21/hong-kong-leader-defends-election-after-single-opposition-figure-makes-it-to-1500-strong-committee',\n",
       " 'type': 'article',\n",
       " 'sectionId': 'world',\n",
       " 'sectionName': 'World news',\n",
       " 'webPublicationDate': '2021-09-21T05:46:48Z',\n",
       " 'webTitle': 'Hong Kong leader defends election after single non-establishment figure picked for 1,500-strong committee',\n",
       " 'webUrl': 'https://www.theguardian.com/world/2021/sep/21/hong-kong-leader-defends-election-after-single-opposition-figure-makes-it-to-1500-strong-committee',\n",
       " 'apiUrl': 'https://content.guardianapis.com/world/2021/sep/21/hong-kong-leader-defends-election-after-single-opposition-figure-makes-it-to-1500-strong-committee',\n",
       " 'isHosted': False,\n",
       " 'pillarId': 'pillar/news',\n",
       " 'pillarName': 'News'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"We grabbed {len(all_results)} articles! The metadata for the first one:\\n\")\n",
    "\n",
    "all_results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the urls and save them to file for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [res['webUrl'] for res in all_results]\n",
    "# urls[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('urls.txt', 'w') as f:\n",
    "    for url in urls:\n",
    "        f.write(f\"{url}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check what kind of page we got:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article', 'gallery', 'interactive', 'liveblog'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types = [res['type'] for res in all_results]\n",
    "set(types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all items are articles. This could be a problem when scraping text, as e.g. liveblog has a more complex structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape article's body from url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all urls, let's retrieve all HTML. Since sometimes the server becomes overloaded and throws a 429 Error Code, we wait a bit before resuming our spamming. We store successful responses in a dictionary, so that it is simple to check which threw an error and still need to be retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = {}\n",
    "while len(articles) < len(urls):\n",
    "    for i, url in enumerate(urls):\n",
    "        if i not in articles:\n",
    "            try:\n",
    "                article = requests.get(url)\n",
    "                article.raise_for_status()\n",
    "                articles[i] = article\n",
    "            except requests.exceptions.RequestException as err:\n",
    "                # print(f\"At article {i}:\\n\")\n",
    "                # print(err)\n",
    "                time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that we successfully retrieved all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_articles: 3000 vs n_urls: 3000\n",
      "codes encountered: {200}\n"
     ]
    }
   ],
   "source": [
    "print(f\"n_articles: {len(articles)} vs n_urls: {len(urls)}\")\n",
    "\n",
    "codes = []\n",
    "for art in articles.values():\n",
    "    codes.append(art.status_code)\n",
    "print(f\"codes encountered: {set(codes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now parse the HTML as we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_response(resp):\n",
    "    soup_article = BeautifulSoup(resp.content, 'html.parser')\n",
    "    body = soup_article.find_all('div', class_='article-body-commercial-selector')\n",
    "    if len(body)==1:\n",
    "        ps = body[0].find_all('p', class_='dcr-s23rjr')\n",
    "        par_list = [p.text for p in ps]\n",
    "        text = \" \".join(par_list)\n",
    "    else:\n",
    "        text = 'Missing'\n",
    "    \n",
    "    return text, len(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = []\n",
    "lengths = []\n",
    "\n",
    "for k, art in articles.items():\n",
    "    text, l_body = text_from_response(art)\n",
    "    cond = text is '' or text is 'Missing'\n",
    "    if not cond:\n",
    "        all_texts.append(text)\n",
    "    lengths.append(l_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2033, 3000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_texts), len(lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some responses have no or empty body, so we don't collect them (note: it should be possible to catch these cases during the HTML parsing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1}\n",
      "{1: 2831, 0: 169}\n"
     ]
    }
   ],
   "source": [
    "# some responses have no body\n",
    "print(set(lengths))\n",
    "\n",
    "# how many?\n",
    "d = {}\n",
    "for i in lengths:\n",
    "    d[i] = d.get(i, 0) + 1 \n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert this to a DataFrame and save it as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2033, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hong Kong’s chief executive, Carrie Lam, has d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>International companies are being forced to re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hong Kong authorities have raided the city’s T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Hong Kong activist Andy Li and paralegal C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For much of the last year Kacey Wong was wakin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content\n",
       "0  Hong Kong’s chief executive, Carrie Lam, has d...\n",
       "1  International companies are being forced to re...\n",
       "2  Hong Kong authorities have raided the city’s T...\n",
       "3  The Hong Kong activist Andy Li and paralegal C...\n",
       "4  For much of the last year Kacey Wong was wakin..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'Content': all_texts})\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"articles.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can re-load the file to check everything is in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hong Kong’s chief executive, Carrie Lam, has d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>International companies are being forced to re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hong Kong authorities have raided the city’s T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Hong Kong activist Andy Li and paralegal C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For much of the last year Kacey Wong was wakin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content\n",
       "0  Hong Kong’s chief executive, Carrie Lam, has d...\n",
       "1  International companies are being forced to re...\n",
       "2  Hong Kong authorities have raided the city’s T...\n",
       "3  The Hong Kong activist Andy Li and paralegal C...\n",
       "4  For much of the last year Kacey Wong was wakin..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"articles.csv\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Content    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we are done. Another way to save text data would be to save each article to a separate .txt file, but for now this will suffice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
